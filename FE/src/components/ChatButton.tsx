import axios from "axios";
import { useEffect, useRef, useState } from "react";
import { IconContext } from "react-icons";
import { BsFillMicFill, BsRecordCircle } from "react-icons/bs";
import { styled } from "styled-components";

const FloatingContainer = styled.div`
  position: fixed;
  width: 100px;
  height: 100px;
  bottom: 0;
  right: 0;
  margin: 35px 25px;
  &:hover {
    height: 300px;
  }
  &:hover .floating-button {
    box-shadow: 0 10px 25px var(--emerald);
    transform: translateY(5px);
    transition: all 0.3s;
  }
`;

const FloatingButton = styled.div<{ $onRec: boolean }>`
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  width: 65px;
  height: 65px;
  background: ${props => (props.$onRec ? "var(--emerald)" : "white")};
  bottom: 0;
  border-radius: 50%;
  left: 0;
  right: 0;
  margin: auto;
  color: white;
  text-align: center;
  z-index: 100;
  box-shadow: ${props =>
    props.$onRec ? "0 10px 25px -5px var(--emerald)" : "0 10px 25px -5px gray"};
  cursor: pointer;
  transition: all 0.3s;
  &:hover {
    transform: translateY(5px);
  }
`;

function ChatButton() {
  const [stream, setStream] = useState<MediaStream>();
  const [media, setMedia] = useState<MediaRecorder>();
  const [onRec, setOnRec] = useState(true);
  const [source, setSource] = useState<MediaStreamAudioSourceNode>();
  const [analyser, setAnalyser] = useState<ScriptProcessorNode>();
  const [audioUrl, setAudioUrl] = useState<any>();
  const [responseAudioUrl, setResponseAudioUrl] = useState<any>();
  // const [audio, setAudio] = useState<Blob>();
  const audioRef = useRef<HTMLAudioElement>(null);

  // function base64ToBlob(base64: any, fileType: string) {
  //   let typeHeader = "data:application/" + fileType + ";base64,"; // base64 í—¤ë” íŒŒì¼ ìœ í˜• ì •ì˜
  //   let audioSrc = typeHeader + base64;
  //   let arr = audioSrc.split(",");
  //   let array = arr[0].match(/:(.*?);/);
  //   let mime = (array && array.length > 1 ? array[1] : fileType) || fileType;
  //   // urlí—¤ë” ì œê±°í•˜ê³  btyeë¡œ ë³€í™˜
  //   let bytes = window.atob(arr[1]);
  //   // ì˜ˆì™¸ë¥¼ ì²˜ë¦¬í•˜ê³  0ë³´ë‹¤ ì‘ì€ ASCII ì½”ë“œë¥¼ 0ë³´ë‹¤ í° ê°’ìœ¼ë¡œ ë³€í™˜
  //   let ab = new ArrayBuffer(bytes.length);
  //   // ë·° ìƒì„±(ë©”ëª¨ë¦¬ì— ì§ì ‘): 8ë¹„íŠ¸ ë¶€í˜¸ ì—†ëŠ” ì •ìˆ˜, ê¸¸ì´ 1ë°”ì´íŠ¸
  //   let ia = new Uint8Array(ab);
  //   for (let i = 0; i < bytes.length; i++) {
  //     ia[i] = bytes.charCodeAt(i);
  //   }
  //   return new Blob([ab], {
  //     type: mime,
  //   });
  // }
  async function sendAudio(file: File) {
    try {
      const formData = new FormData();
      // formData.append(
      //   "audio.mp3",
      //   new Blob([JSON.stringify(file)], {
      //     type: "audio/mp3",
      //   }),
      // );
      console.log("file", file);
      formData.append("voiceFile", file);
      const response = await axios.post("/api/chatbot/v1/talk", formData, {
        headers: {
          "Content-Type": "multipart/form-data",
        },
      });
      console.log(response);
      const blob = new Blob([response.data], { type: "audio/mpeg" });
      console.log("resBlob", blob);
      const blobUrl = URL.createObjectURL(blob);
      console.log(blobUrl);
      // setAudioUrl(blobUrl);
      // const audioElement = new Audio();
      // audioElement.src = blobUrl;
      // setResponseAudioUrl(blobUrl);
      // audioElement.volume = 0.5;
      // audioElement.play();
      // base64ToBlob(response.data, 'mp3');
      // setAudio(base64ToBlob(response.data, "mp3"));
    } catch (error) {
      console.log(error);
    }
  }
  const onRecAudio = () => {
    // ìŒì›ì •ë³´ë¥¼ ë‹´ì€ ë…¸ë“œë¥¼ ìƒì„±í•˜ê±°ë‚˜ ìŒì›ì„ ì‹¤í–‰ë˜ëŠ” ë””ì½”ë”© ì‹œí‚¤ëŠ” ì¼ì„ í•œë‹¤
    const audioCtx = new window.AudioContext();
    // ìë°”ìŠ¤í¬ë¦½íŠ¸ë¥¼ í†µí•´ ìŒì›ì˜ ì§„í–‰ìƒíƒœì— ì§ì ‘ì ‘ê·¼ì— ì‚¬ìš©ëœë‹¤.
    const analyser = audioCtx.createScriptProcessor(0, 1, 1);
    setAnalyser(analyser);

    function makeSound(stream: MediaStream) {
      // ë‚´ ì»´í“¨í„°ì˜ ë§ˆì´í¬ë‚˜ ë‹¤ë¥¸ ì†ŒìŠ¤ë¥¼ í†µí•´ ë°œìƒí•œ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì˜ ì •ë³´ë¥¼ ë³´ì—¬ì¤€ë‹¤.
      const source = audioCtx.createMediaStreamSource(stream);
      setSource(source);
      source.connect(analyser);
      analyser.connect(audioCtx.destination);
    }
    // ë§ˆì´í¬ ì‚¬ìš© ê¶Œí•œ íšë“
    navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorder.start();
      setStream(stream);
      setMedia(mediaRecorder);
      makeSound(stream);

      analyser.onaudioprocess = function (e) {
        // 3ë¶„(180ì´ˆ) ì§€ë‚˜ë©´ ìë™ìœ¼ë¡œ ìŒì„± ì €ì¥ ë° ë…¹ìŒ ì¤‘ì§€
        if (e.playbackTime > 60) {
          stream.getAudioTracks().forEach(function (track) {
            track.stop();
          });
          mediaRecorder.stop();
          // ë©”ì„œë“œê°€ í˜¸ì¶œ ëœ ë…¸ë“œ ì—°ê²° í•´ì œ
          analyser.disconnect();
          audioCtx.createMediaStreamSource(stream).disconnect();

          mediaRecorder.ondataavailable = function (e) {
            setAudioUrl(e.data);
            setOnRec(true);
          };
        } else {
          setOnRec(false);
        }
      };
    });
  };
  // ì‚¬ìš©ìê°€ ìŒì„± ë…¹ìŒì„ ì¤‘ì§€ í–ˆì„ ë•Œ
  const offRecAudio = () => {
    // dataavailable ì´ë²¤íŠ¸ë¡œ Blob ë°ì´í„°ì— ëŒ€í•œ ì‘ë‹µì„ ë°›ì„ ìˆ˜ ìˆìŒ

    media!.ondataavailable = function (e: any) {
      console.log(e.data);
      setAudioUrl(e.data);
      console.log(URL.createObjectURL(e.data));
      setOnRec(true);
      const sound = new File([e.data], "sample.mp3", {
        lastModified: new Date().getTime(),
        type: "audio/mpeg",
      });
      // console.log("sound", sound);
      sendAudio(sound);
    };

    // ëª¨ë“  íŠ¸ë™ì—ì„œ stop()ì„ í˜¸ì¶œí•´ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„ ì •ì§€
    stream!.getAudioTracks().forEach(function (track) {
      track.stop();
    });

    // ë¯¸ë””ì–´ ìº¡ì²˜ ì¤‘ì§€
    media!.stop();

    // ë©”ì„œë“œê°€ í˜¸ì¶œ ëœ ë…¸ë“œ ì—°ê²° í•´ì œ
    analyser!.disconnect();
    source!.disconnect();

    // if (audioUrl) {
    //   console.log(URL.createObjectURL(audioUrl)); // ì¶œë ¥ëœ ë§í¬ì—ì„œ ë…¹ìŒëœ ì˜¤ë””ì˜¤ í™•ì¸ ê°€ëŠ¥
    // }

    // File ìƒì„±ìë¥¼ ì‚¬ìš©í•´ íŒŒì¼ë¡œ ë³€í™˜
    // const sound = new File([audioUrl], "sample.mp3", {
    //   lastModified: new Date().getTime(),
    //   type: "audio/mpeg",
    // });

    // ğŸ˜€ğŸ˜€ğŸ˜€
    // console.log(sound); // File ì •ë³´ ì¶œë ¥
    // sendAudio(sound);
  };
  // useEffect(() => {
  //   if (audio) {
  //     // MPEG ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ Blobì„ ìƒì„±
  //     console.log(audio);
  //     // const blob = new Blob([audio], { type: "audio/mpeg" });

  //     // Blobì„ URLë¡œ ë³€í™˜
  //     const responseAudioURL = URL.createObjectURL(audio);
  //     console.log("response", responseAudioURL);
  //     console.log(audioRef.current);
  //     audioRef.current.src = responseAudioURL;
  //     // ì˜¤ë””ì˜¤ ìš”ì†Œì— URL ì„¤ì •
  //     // ì˜¤ë””ì˜¤ ì¬ìƒ
  //     // audioRef.current.play();
  //   }
  // }, [audio]);

  return (
    <>
      <FloatingContainer>
        {onRec ? (
          <FloatingButton onClick={onRecAudio} $onRec={onRec}>
            <IconContext.Provider value={{ color: "black" }}>
              <BsFillMicFill size={40} />
            </IconContext.Provider>
          </FloatingButton>
        ) : (
          <FloatingButton onClick={offRecAudio} $onRec={onRec}>
            <IconContext.Provider value={{ color: "red" }}>
              <BsRecordCircle size={40} color="red" />
            </IconContext.Provider>
          </FloatingButton>
        )}
      </FloatingContainer>
      {responseAudioUrl && <audio ref={audioRef} src={responseAudioUrl} controls />}
      {audioUrl && <audio src={URL.createObjectURL(audioUrl)} controls></audio>}
    </>
  );
}

export default ChatButton;
